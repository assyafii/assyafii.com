<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Summary docs on M. Luthfi As Syafii</title>
    <link>/docs/</link>
    <description>Recent content in Summary docs on M. Luthfi As Syafii</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 28 Nov 2018 15:14:39 +1000</lastBuildDate><atom:link href="/docs/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Deploy CRUD using AWS API Gateway, Serverless Lambda and RDS</title>
      <link>/docs/deploy-crud-using-aws-api-gateway-serverless-lambda-and-rds-&#43;-openstack/</link>
      <pubDate>Wed, 15 Jun 2022 00:00:00 +0000</pubDate>
      
      <guid>/docs/deploy-crud-using-aws-api-gateway-serverless-lambda-and-rds-&#43;-openstack/</guid>
      <description>Specification : AWS, API Gateway, Serverless, Lambda, RDS, Postman
 Lab Topology  Step-by-step  Create IAM role for allow configuration Create Database table with DynamoDB Create AWS API Gateway service Create Lambda function Testing CRUD with postman Verify  A. Create IAM role First step is create IAM role to allow Lambda function to call AWS services, for it you can follow guide bellow :
 Login to your AWS console, search and chose IAM menu  Choose Roles and create role  Choose AWS Services -&amp;gt; Lambda and Next   And you can see menu bellow   For integrate lambda with RDS &amp;amp; cloudwatch, wee need filter &amp;amp; checklist cloudwatchfullaccess   And the last one, search dynamodb and checklist full access permissions   Add rolename   Verify you already added two roles for it, and create role     B.</description>
    </item>
    
    <item>
      <title>Deploy PortWorx storage in kubernetes</title>
      <link>/docs/deploy-portworx-storage-in-kubernetes/</link>
      <pubDate>Sun, 03 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>/docs/deploy-portworx-storage-in-kubernetes/</guid>
      <description>Specification : Kubernetes, PortWorx, Storage
 PortWorx storage cluster Portworx by Pure Storage is a cloud native storage solution, provides a fully integrated solution for persistent storage, data protection, disaster recovery, data security, cross-cloud and data migrations, and automated capacity management for applications running on Kubernetes. If you see in each of documents, portworx have big IOPS &amp;amp; Bandwidth.
 Lab Topology    IP Address Nodes     10.</description>
    </item>
    
    <item>
      <title>5G Cloud Native Simulation with Open5Gs</title>
      <link>/docs/5g-cloud-native-simulation-with-open5gs/</link>
      <pubDate>Sat, 02 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>/docs/5g-cloud-native-simulation-with-open5gs/</guid>
      <description>Specification : Kubernetes, HELM, Istio, Open5Gs, ROOK, CEPH, Rancher
 Lab Topology Create Namespaces for practices kubectl create ns open5gs Install Service mesh Istio (optional) curl -L https://istio.io/downloadIstio | sh - cd istio-1.12.1 export PATH=$PWD/bin:$PATH istioctl install --set profile=demo -y Add a namespace label to instruct Istio to automatically inject Envoy sidecar proxies when you deploy your application later:
kubectl label namespace open5gs istio-injection=enabled Install Addons packages
cd ~/istio-1.</description>
    </item>
    
    <item>
      <title>Deploy Magmacore 5G on AWS</title>
      <link>/docs/deploy-magmacore-5g-on-aws/</link>
      <pubDate>Sat, 02 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>/docs/deploy-magmacore-5g-on-aws/</guid>
      <description>Specification : Amazon Web Services, Magmacore, 5G, Cloud
 Deploy Cloudstrapper  Access AWS Marketplace and search for “Magma Cloudstrapper”   On the Product Overview page, click Continue to Subscribe.   On the Subscribe to this software page, confirm Accept Terms and click Continue to Configuration.   On the Configure this software page, choose Delivery Method, Software Version, and Region. The only default we recommend you change is the Region.</description>
    </item>
    
    <item>
      <title>Deploy storage cluster ROOK with CEPH in Kubernetes</title>
      <link>/docs/deploy-storage-cluster-rook-with-ceph-in-kubernetes/</link>
      <pubDate>Sat, 02 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>/docs/deploy-storage-cluster-rook-with-ceph-in-kubernetes/</guid>
      <description>Specification : Kubernetes, ROOK, CEPH
 Lab Topology You can check installation kubernetes cluster in previous documentation, https://assyafii.com/docs/install-kubernetes-cluster-multi-master-ha/  Storages nodes disks We use 3 disks extended (vdb, vdc, vdd) in each of storage-nodes, total 6 disks for rook cluster.
Detail disks Master node  Clone ROOK Project cd ~ git clone --single-branch --branch release-1.7 https://github.com/rook/rook.git Deploy the Rook Operator cd rook/cluster/examples/kubernetes/ceph kubectl create -f crds.yaml kubectl create -f common.</description>
    </item>
    
    <item>
      <title>Install Kubernetes cluster multi Master High Availability</title>
      <link>/docs/install-kubernetes-cluster-multi-master-ha/</link>
      <pubDate>Sat, 02 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>/docs/install-kubernetes-cluster-multi-master-ha/</guid>
      <description>Specification : Calico, Containerd, Haproxy, Kubernetes v1.22.x
 Lab Topology First, prepare all VM All Nodes except LB Nodes  Set mapping hostname nano /etc/hosts Install packages containerd Load overlay and br_netfilter kernal modules.
cat &amp;lt;&amp;lt;EOF | sudo tee /etc/modules-load.d/containerd.conf overlay br_netfilter EOF sudo modprobe overlay sudo modprobe br_netfilter Set these system configurations for Kubernetes networking cat &amp;lt;&amp;lt;EOF | sudo tee /etc/sysctl.d/99-kubernetes-cri.conf net.bridge.bridge-nf-call-iptables = 1 net.ipv4.ip_forward = 1 net.</description>
    </item>
    
  </channel>
</rss>
